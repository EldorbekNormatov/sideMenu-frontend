<!doctype html>
<html lang="uz">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>iOS-Style A4 Scanner ‚Äî Full Clone</title>

  <!-- Tailwind CDN -->
  <script src="https://cdn.tailwindcss.com"></script>

  <!-- OpenCV.js (async) -->
  <script async src="https://docs.opencv.org/4.x/opencv.js"></script>

  <style>
    .video-box { aspect-ratio: 3/4; object-fit: cover; border-radius: 12px; }
    .overlay-canvas { position: absolute; inset: 0; pointer-events: none; }
    .focus-ring {
      position: absolute; width: 80px; height: 80px;
      border: 4px solid #fbbf24; border-radius: 9999px;
      display: none; pointer-events: none; transform: translate(-50%,-50%);
    }
    /* glow for border (extra) */
    .glow {
      filter: drop-shadow(0 0 8px rgba(255,200,0,0.8));
    }
  </style>
</head>

<body class="bg-slate-900 text-white min-h-screen flex justify-center py-8">
  <div class="w-full max-w-md px-4">
    <h1 class="text-xl font-semibold mb-3">üìÑ iOS-Style A4 Scanner (Full Clone)</h1>

    <div class="flex gap-3 mb-3">
      <button id="startBtn" class="flex-1 bg-slate-700 py-3 rounded-full">üì∏ Open Camera</button>
      <button id="toggleAuto" class="px-3 bg-slate-600 rounded-full">‚öôÔ∏è Auto-capture: ON</button>
    </div>

    <p id="status" class="text-xs text-yellow-300 min-h-[20px] mb-2"></p>
    <div id="camera-box" class="relative hidden">
      <div id="infoOverlay" class="absolute left-1/2 -translate-x-1/2 bottom-3 bg-black/60 px-3 py-1 rounded-full text-xs z-20"></div>
      <video id="video" autoplay playsinline class="w-full bg-black video-box"></video>
      <canvas id="overlay" class="overlay-canvas z-10"></canvas>
      <div id="focusRing" class="focus-ring z-30"></div>
      <button id="captureBtn" class="w-full mt-3 bg-emerald-500 hover:bg-emerald-400 py-3 rounded-full z-20">üì∑ Capture</button>
    </div>

    <h3 class="mt-6 font-bold text-sm">Captured</h3>
    <div id="preview" class="space-y-2 mt-2"></div>
  </div>

<script>
/* ===========================
   CONFIG & STATE
   =========================== */
const API_BASE = "https://panel.nvmailer.uz"; // (optional) backend
const CHECK_ENDPOINT = API_BASE + "/photo-check";
const SAVE_ENDPOINT = API_BASE + "/photo-save";

let stream = null;
let videoTrack = null;
let cvReady = false;
let lastQuad = null;               // current averaged quad
let rawQuad = null;                // latest detected quad before smoothing
let quadHistory = [];              // for smoothing (moving average)
const QUAD_HISTORY_LEN = 6;        // smoothing window
let stableFrames = 0;
let autoCaptureEnabled = true;
let lastCaptureAt = 0;
let images = [];

/* ===========================
   DOM
   =========================== */
const startBtn = document.getElementById("startBtn");
const toggleAuto = document.getElementById("toggleAuto");
const statusEl = document.getElementById("status");
const cameraBox = document.getElementById("camera-box");
const videoEl = document.getElementById("video");
const overlay = document.getElementById("overlay");
const overlayCtx = overlay.getContext("2d");
const infoOverlay = document.getElementById("infoOverlay");
const captureBtn = document.getElementById("captureBtn");
const previewEl = document.getElementById("preview");

/* ===========================
   UTIL FUNCTIONS
   =========================== */
function setStatus(text, color="yellow"){
  statusEl.textContent = text;
  statusEl.className = color === "green" ? "text-green-400 text-xs" : color === "red" ? "text-red-400 text-xs" : "text-yellow-300 text-xs";
}
function setInfo(text=""){ infoOverlay.textContent = text; }

// distance between two points
function pDist(a,b){ return Math.hypot(a.x-b.x, a.y-b.y); }

// area of polygon (4 points)
function polyArea(pts){
  let a=0;
  for(let i=0;i<pts.length;i++){
    const j=(i+1)%pts.length;
    a += pts[i].x*pts[j].y - pts[j].x*pts[i].y;
  }
  return Math.abs(a/2);
}

// order quad to [tl,tr,br,bl]
function orderQuad(pts){
  const sum = pts.map(p=>p.x+p.y);
  const diff = pts.map(p=>p.y-p.x);
  const tl = pts[sum.indexOf(Math.min(...sum))];
  const br = pts[sum.indexOf(Math.max(...sum))];
  const tr = pts[diff.indexOf(Math.min(...diff))];
  const bl = pts[diff.indexOf(Math.max(...diff))];
  return [tl,tr,br,bl];
}
function isValidQuad(q){ return q && q.length===4 && q.every(p=>p.x>2 && p.y>2); }

/* Smooth quad: moving average over quadHistory */
function smoothQuad(newQuad){
  if(!isValidQuad(newQuad)) return null;
  quadHistory.push(newQuad);
  if(quadHistory.length > QUAD_HISTORY_LEN) quadHistory.shift();

  const n = quadHistory.length;
  const avg = [{x:0,y:0},{x:0,y:0},{x:0,y:0},{x:0,y:0}];
  quadHistory.forEach(q=>{
    for(let i=0;i<4;i++){ avg[i].x += q[i].x; avg[i].y += q[i].y; }
  });
  for(let i=0;i<4;i++){ avg[i].x /= n; avg[i].y /= n; }
  return avg;
}

/* measure motion between two quads: avg point distance */
function quadMotion(a,b){
  if(!isValidQuad(a) || !isValidQuad(b)) return Infinity;
  let s=0;
  for(let i=0;i<4;i++) s += pDist(a[i], b[i]);
  return s/4;
}

/* brightness check (mean luminance) from a canvas */
function meanLuminanceFromCanvas(c){
  const ctx = c.getContext('2d');
  const data = ctx.getImageData(0,0,c.width,c.height).data;
  let s=0, n=0;
  for(let i=0;i<data.length;i+=4){
    // luma approximation
    s += 0.2126*data[i] + 0.7152*data[i+1] + 0.0722*data[i+2];
    n++;
  }
  return s/n;
}

/* play a small beep for feedback */
function beep(){
  try{
    const ctx = new (window.AudioContext || window.webkitAudioContext)();
    const o = ctx.createOscillator();
    const g = ctx.createGain();
    o.type = 'sine';
    o.frequency.value = 880;
    o.connect(g); g.connect(ctx.destination);
    o.start();
    g.gain.setValueAtTime(0.0001, ctx.currentTime);
    g.gain.exponentialRampToValueAtTime(0.05, ctx.currentTime + 0.01);
    g.gain.exponentialRampToValueAtTime(0.0001, ctx.currentTime + 0.18);
    o.stop(ctx.currentTime + 0.2);
  }catch(e){/* ignore */ }
}

/* ===========================
   WAIT FOR OPENCV
   =========================== */
(function waitForCV(){
  const t = setInterval(()=>{
    if(window.cv && cv.Mat){
      cv.onRuntimeInitialized = () => {
        cvReady = true;
        setStatus("OpenCV ready", "green");
      };
      clearInterval(t);
    }
  }, 120);
})();

/* ===========================
   DETECTION LOOP (with highlight + smoothing + auto-capture)
   =========================== */
function startDetectionLoop(){
  const detectCanvas = document.createElement('canvas');
  const dctx = detectCanvas.getContext('2d');

  // previous smoothed quad for motion detection
  let prevSmoothed = null;

  async function step(){
    if(!stream) return;
    if(!cvReady || !videoEl.videoWidth){
      requestAnimationFrame(step);
      return;
    }

    const w = videoEl.videoWidth;
    const h = videoEl.videoHeight;
    detectCanvas.width = w; detectCanvas.height = h;
    overlay.width = w; overlay.height = h;

    dctx.drawImage(videoEl, 0, 0, w, h);

    // Opencv processing
    let src = cv.imread(detectCanvas);
    let gray = new cv.Mat();
    let blur = new cv.Mat();
    let edges = new cv.Mat();
    let contours = new cv.MatVector();
    let hierarchy = new cv.Mat();

    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
    cv.GaussianBlur(gray, blur, new cv.Size(5,5), 0);
    cv.Canny(blur, edges, 60, 180);
    cv.findContours(edges, contours, hierarchy, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE);

    // find largest 4-point contour
    let bestArea = 0; let bestQuadMat = null;
    for(let i=0;i<contours.size();i++){
      const cnt = contours.get(i);
      const peri = cv.arcLength(cnt, true);
      const approx = new cv.Mat();
      cv.approxPolyDP(cnt, approx, peri * 0.02, true);
      if(approx.rows === 4){
        const area = cv.contourArea(approx);
        if(area > bestArea){
          bestArea = area;
          if(bestQuadMat) bestQuadMat.delete();
          bestQuadMat = approx;
        } else approx.delete();
      } else approx.delete();
      cnt.delete();
    }

    // Reset overlay
    overlayCtx.clearRect(0,0,w,h);
    // Default info
    setInfo("");

    if(bestQuadMat && bestArea > w*h*0.10){
      // raw points from bestQuadMat
      const pts = [];
      for(let i=0;i<4;i++) pts.push({ x: bestQuadMat.intAt(i,0), y: bestQuadMat.intAt(i,1) });

      rawQuad = orderQuad(pts);
      // smoothing
      const sm = smoothQuad(rawQuad);
      lastQuad = sm;
      // draw highlight + mask + glow
      overlayCtx.clearRect(0,0,w,h);

      // dark mask
      overlayCtx.fillStyle = "rgba(0,0,0,0.55)";
      overlayCtx.fillRect(0,0,w,h);

      // path
      overlayCtx.save();
      overlayCtx.beginPath();
      overlayCtx.moveTo(sm[0].x, sm[0].y);
      overlayCtx.lineTo(sm[1].x, sm[1].y);
      overlayCtx.lineTo(sm[2].x, sm[2].y);
      overlayCtx.lineTo(sm[3].x, sm[3].y);
      overlayCtx.closePath();

      // cut out
      overlayCtx.globalCompositeOperation = "destination-out";
      overlayCtx.fill();
      overlayCtx.restore();

      // yellow fill
      overlayCtx.fillStyle = "rgba(255,220,0,0.32)";
      overlayCtx.beginPath();
      overlayCtx.moveTo(sm[0].x, sm[0].y);
      overlayCtx.lineTo(sm[1].x, sm[1].y);
      overlayCtx.lineTo(sm[2].x, sm[2].y);
      overlayCtx.lineTo(sm[3].x, sm[3].y);
      overlayCtx.closePath();
      overlayCtx.fill();

      // glow border (draw twice: wide translucent + narrow solid)
      overlayCtx.lineWidth = Math.max(3, Math.round(Math.min(w,h)*0.004));
      overlayCtx.strokeStyle = "rgba(255,200,0,0.28)";
      overlayCtx.beginPath();
      overlayCtx.moveTo(sm[0].x, sm[0].y);
      overlayCtx.lineTo(sm[1].x, sm[1].y);
      overlayCtx.lineTo(sm[2].x, sm[2].y);
      overlayCtx.lineTo(sm[3].x, sm[3].y);
      overlayCtx.closePath();
      overlayCtx.stroke();

      overlayCtx.lineWidth = Math.max(2, Math.round(Math.min(w,h)*0.002));
      overlayCtx.strokeStyle = "rgb(255,200,0)";
      overlayCtx.beginPath();
      overlayCtx.moveTo(sm[0].x, sm[0].y);
      overlayCtx.lineTo(sm[1].x, sm[1].y);
      overlayCtx.lineTo(sm[2].x, sm[2].y);
      overlayCtx.lineTo(sm[3].x, sm[3].y);
      overlayCtx.closePath();
      overlayCtx.stroke();

      // info text
      setInfo("üìÑ Hujjat topildi ‚Äî barqaror joylang");

      // stability & motion checks for auto-capture
      // area ratio
      const areaRatio = bestArea / (w*h);
      const brightness = meanLuminanceFromCanvas(detectCanvas); // 0-255
      // compute motion vs prevSmoothed
      const motion = prevSmoothed ? quadMotion(sm, prevSmoothed) : 9999;

      // conditions similar to iOS: large enough, low motion, good brightness
      const goodArea = areaRatio > 0.30;          // hujjat ekranning >30%
      const lowMotion = motion < Math.max(w,h) * 0.007; // small movement threshold
      const goodLight = brightness > 50;          // tune as needed

      if(goodArea && lowMotion && goodLight && autoCaptureEnabled){
        stableFrames++;
      } else {
        stableFrames = Math.max(0, stableFrames - 1); // decay
      }

      // if stable for N frames and last capture > 1500ms ago -> auto capture
      if(stableFrames >= 5 && (Date.now() - lastCaptureAt) > 1500){
        stableFrames = 0;
        lastCaptureAt = Date.now();
        // visual feedback
        beep();
        // auto-capture
        triggerCapture(true); // true means auto
      }

      prevSmoothed = sm;

    } else {
      // nothing reliable
      rawQuad = null;
      lastQuad = null;
      quadHistory = []; // reset smoothing quickly if lost
      stableFrames = 0;
      overlayCtx.clearRect(0,0,w,h);
      setInfo("Hujjatni to‚Äòliq kadrga joylashtiring");
    }

    // cleanup
    src.delete(); gray.delete(); blur.delete(); edges.delete(); contours.delete(); hierarchy.delete();
    if(bestQuadMat) bestQuadMat.delete();

    requestAnimationFrame(step);
  }

  step();
}

/* ===========================
   CAMERA OPEN
   =========================== */
startBtn.addEventListener("click", async ()=>{
  try{
    setStatus("Kamera ochilyapti...");
    stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: { ideal: "environment" }, width: { ideal: 1920 }, height: { ideal: 1080 }, frameRate: { ideal: 30 } },
      audio: false
    });
    videoTrack = stream.getVideoTracks()[0];
    videoEl.srcObject = stream;
    cameraBox.classList.remove("hidden");
    setStatus("Kamera tayyor", "green");

    startDetectionLoop();
  } catch(e){
    console.error(e);
    setStatus("Kamera ochib bo'lmadi", "red");
  }
});

/* ===========================
   CAPTURE & IMAGE ENHANCE
   =========================== */
// capture trigger wrapper (autoFlag used to mark auto capture)
async function triggerCapture(autoFlag=false){
  if(!videoEl.videoWidth) return;
  setStatus(autoFlag ? "Auto-capture..." : "Capturing...");

  // draw current frame to base canvas
  const base = document.createElement('canvas');
  base.width = videoEl.videoWidth;
  base.height = videoEl.videoHeight;
  const bctx = base.getContext('2d');
  bctx.drawImage(videoEl, 0, 0, base.width, base.height);

  // if we have lastQuad (smoothed), do perspective warp via OpenCV
  let finalCanvas = base;
  if(cvReady && lastQuad && isValidQuad(lastQuad)){
    try{
      const pts = lastQuad;
      const w1 = Math.hypot(pts[1].x-pts[0].x, pts[1].y-pts[0].y);
      const w2 = Math.hypot(pts[2].x-pts[3].x, pts[2].y-pts[3].y);
      const h1 = Math.hypot(pts[3].x-pts[0].x, pts[3].y-pts[0].y);
      const h2 = Math.hypot(pts[2].x-pts[1].x, pts[2].y-pts[1].y);
      const dstW = Math.max(Math.floor(w1), Math.floor(w2));
      const dstH = Math.max(Math.floor(h1), Math.floor(h2));

      // OpenCV warp
      const src = cv.imread(base);
      const dst = new cv.Mat();
      const srcTri = cv.matFromArray(4,1,cv.CV_32FC2,[
        pts[0].x, pts[0].y,
        pts[1].x, pts[1].y,
        pts[2].x, pts[2].y,
        pts[3].x, pts[3].y
      ]);
      const dstTri = cv.matFromArray(4,1,cv.CV_32FC2,[
        0,0,
        dstW,0,
        dstW,dstH,
        0,dstH
      ]);
      const M = cv.getPerspectiveTransform(srcTri, dstTri);
      cv.warpPerspective(src, dst, M, new cv.Size(dstW, dstH));

      // enhance: CLAHE (contrast limited adaptive histogram equalization)
      try{
        let lab = new cv.Mat();
        cv.cvtColor(dst, lab, cv.COLOR_RGBA2Lab);
        let labPlanes = new cv.MatVector();
        cv.split(lab, labPlanes);
        let L = labPlanes.get(0);

        // CLAHE
        let clahe = new cv.CLAHE(2.0, new cv.Size(8,8));
        let Lclahe = new cv.Mat();
        clahe.apply(L, Lclahe);

        // merge back
        labPlanes.set(0, Lclahe);
        cv.merge(labPlanes, lab);
        let enhanced = new cv.Mat();
        cv.cvtColor(lab, enhanced, cv.COLOR_Lab2RGBA);

        // bilateral filter to reduce noise but keep edges
        let smooth = new cv.Mat();
        cv.bilateralFilter(enhanced, smooth, 9, 75, 75);

        // unsharp mask (sharpen): result = enhanced * 1.5 - smooth * 0.5
        let sharpen = new cv.Mat();
        cv.addWeighted(enhanced, 1.5, smooth, -0.5, 0, sharpen);

        // convert sharpen to canvas
        finalCanvas = document.createElement('canvas');
        finalCanvas.width = sharpen.cols; finalCanvas.height = sharpen.rows;
        cv.imshow(finalCanvas, sharpen);

        // cleanup mats
        L.delete(); Lclahe.delete(); labPlanes.delete(); lab.delete();
        clahe.delete(); enhanced.delete(); smooth.delete(); sharpen.delete();
      } catch(e){
        // if CLAHE not available or fails, fallback to simple warp output
        finalCanvas = document.createElement('canvas');
        finalCanvas.width = dst.cols; finalCanvas.height = dst.rows;
        cv.imshow(finalCanvas, dst);
      }

      // free mats
      src.delete(); dst.delete(); srcTri.delete(); dstTri.delete(); M.delete();
    } catch(e){
      console.error("Warp/enhance failed:", e);
      // fallback: base
      finalCanvas = base;
    }
  }

  // Make blob
  const blob = await new Promise(res => finalCanvas.toBlob(res, "image/jpeg", 0.92));
  if(!blob){ setStatus("Capture error", "red"); return; }

  // Save locally (preview)
  const url = URL.createObjectURL(blob);
  images.push({ blob, url });
  renderPreview();

  setStatus("Saved", "green");
}

/* bind capture button */
captureBtn.addEventListener("click", ()=> triggerCapture(false));

/* ===========================
   PREVIEW
   =========================== */
function renderPreview(){
  previewEl.innerHTML = "";
  images.forEach((it, idx)=>{
    const box = document.createElement('div');
    box.className = "bg-slate-800 p-2 rounded-xl border border-slate-700 flex items-center gap-3";

    const img = document.createElement('img');
    img.src = it.url;
    img.className = "w-24 h-24 object-cover rounded";
    box.appendChild(img);

    const dl = document.createElement('a');
    dl.href = it.url;
    dl.download = `scan_${idx+1}.jpg`;
    dl.className = "ml-auto px-2 py-1 bg-blue-600 rounded text-xs";
    dl.textContent = "‚¨áÔ∏è";
    box.appendChild(dl);

    const del = document.createElement('button');
    del.className = "ml-2 px-2 py-1 bg-red-600 rounded text-xs";
    del.textContent = "üóë";
    del.onclick = ()=> {
      images.splice(idx,1);
      renderPreview();
    };
    box.appendChild(del);

    previewEl.appendChild(box);
  });
}

/* ===========================
   TOGGLE AUTO CAPTURE
   =========================== */
toggleAuto.addEventListener("click", ()=>{
  autoCaptureEnabled = !autoCaptureEnabled;
  toggleAuto.textContent = `‚öôÔ∏è Auto-capture: ${autoCaptureEnabled ? "ON" : "OFF"}`;
});

/* ===========================
   CLEANUP
   =========================== */
window.addEventListener("beforeunload", ()=>{
  if(stream) stream.getTracks().forEach(t=>t.stop());
});

</script>
</body>
</html>
