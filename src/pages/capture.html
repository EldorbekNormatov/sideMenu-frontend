<!doctype html>
<html lang="uz">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Fast Capture ‚Äì AI Scanner (MediaPipe)</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <!-- jsPDF for multi-page PDF generation -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jspdf/2.5.1/jspdf.umd.min.js"></script>

  <!-- Tell Telegram WebApp we are ready (important for permissions inside Telegram iframe) -->
  <script>
    try {
      if (window.Telegram?.WebApp) {
        Telegram.WebApp.ready();
      }
    } catch(e){
      console.warn('Telegram WebApp ready error', e);
    }
  </script>

  <style>
    body { background:#0f172a; color:white; }
    #overlayCanvas { position:absolute; inset:0; pointer-events:none; z-index:10; }
    #focusRing { transition: opacity .2s, transform .2s; }
  </style>
</head>
<body>
<div class="max-w-md mx-auto p-4">
  <h2 class="text-xl font-bold mb-4">Fast Capture (AI)</h2>

  <div class="flex gap-3 mb-3">
    <button id="startBtn" class="flex-1 bg-slate-700 p-3 rounded-full">üì∏ Open Camera</button>
    <button id="saveAllBtn" class="flex-1 bg-blue-600 p-3 rounded-full hidden">üíæ Upload / Save PDF</button>
  </div>

  <p id="status" class="text-xs min-h-[20px] text-yellow-300"></p>

  <div id="cameraBox" class="hidden mt-4 relative">
    <div id="infoOverlay" class="absolute bottom-3 left-1/2 -translate-x-1/2 bg-slate-900/70 px-3 py-1 rounded-full text-xs"></div>
    <video id="video" autoplay playsinline class="w-full rounded-xl bg-black aspect-[3/4] object-cover"></video>
    <canvas id="overlayCanvas"></canvas>
    <div id="focusRing" class="absolute w-20 h-20 rounded-full border-4 border-yellow-300 hidden" style="pointer-events:none;"></div>
    <button id="captureBtn" class="w-full mt-3 bg-emerald-500 p-3 rounded-full">üì∑ Capture</button>
  </div>

  <h3 class="mt-6 font-bold text-sm">Received Photos</h3>
  <div id="preview" class="space-y-2 mt-2"></div>
</div>

<script type="module">
/* ===========================
   MediaPipe Tasks Vision setup
   =========================== */
import { FilesetResolver, DocumentProcessor } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.1/dist/tasks-vision.js";

const STATUS = document.getElementById('status');
const INFO = document.getElementById('infoOverlay');
const videoEl = document.getElementById('video');
const overlay = document.getElementById('overlayCanvas');
const octx = overlay.getContext('2d');
const startBtn = document.getElementById('startBtn');
const captureBtn = document.getElementById('captureBtn');
const cameraBox = document.getElementById('cameraBox');
const previewEl = document.getElementById('preview');
const saveAllBtn = document.getElementById('saveAllBtn');

let stream=null, videoTrack=null;
let images = []; // {canvas, blob, url}
let detector = null;
let autoBusy=false;
let stableCount=0;
const STABLE_FRAMES = 4;
const MOVE_THR = 60; // px total quad distance for stability

function setStatus(msg, type='yellow'){
  STATUS.textContent = msg;
  STATUS.className = type==='green' ? 'text-green-400' : type==='red' ? 'text-red-400' : 'text-yellow-300';
}
function setInfo(msg){ INFO.textContent = msg; }

function drawQuadOnOverlay(vertices){
  octx.clearRect(0,0,overlay.width,overlay.height);
  if(!vertices) return;
  try {
    octx.beginPath();
    const toPx = v=>[v.x*overlay.width, v.y*overlay.height];
    const [a,b,c,d] = vertices.map(toPx);
    octx.moveTo(a[0],a[1]);
    octx.lineTo(b[0],b[1]);
    octx.lineTo(c[0],c[1]);
    octx.lineTo(d[0],d[1]);
    octx.closePath();
    octx.lineWidth=4;
    octx.strokeStyle='lime';
    octx.stroke();
  } catch(e){ console.warn('drawQuad error',e); }
}

/* -------------------------
   Load MediaPipe Document model
   ------------------------- */
async function initDetector(){
  setStatus('Loading AI model...');
  try {
    const vision = await FilesetResolver.forVisionTasks(
      "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.1/wasm"
    );
    detector = await DocumentProcessor.createFromOptions(vision, {
      baseOptions: { modelAssetPath: "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.1/models/document-processor.task" },
      runningMode: "VIDEO"
    });
    setStatus('Model loaded','green');
  } catch(e){
    console.error('Model init failed', e);
    setStatus('Model load failed ‚Äî check network','red');
    throw e;
  }
}

/* -------------------------
   Camera start (with Telegram permission fallback)
   ------------------------- */
async function startCameraFlow(){
  // If in Telegram WebApp, request camera permission via Telegram API first
  try {
    if (window.Telegram?.WebApp?.requestPermission) {
      try {
        await Telegram.WebApp.requestPermission("camera");
      } catch(e){
        console.warn('Telegram.requestPermission denied or failed', e);
        // continue to try navigator.getUserMedia ‚Äî browser will ask permission
      }
    }
  } catch(e){ console.warn('requestPermission wrapper error', e); }

  try {
    setStatus('Opening camera...');
    stream = await navigator.mediaDevices.getUserMedia({
      video:{ facingMode: { ideal: "environment" }, width: { ideal: 1280 }, height: { ideal: 720 } },
      audio:false
    });
  } catch(e){
    console.error('getUserMedia failed', e);
    setStatus('‚ùå Camera permission denied or unavailable','red');
    return false;
  }

  videoTrack = stream.getVideoTracks()[0];
  videoEl.srcObject = stream;
  cameraBox.classList.remove('hidden');
  setStatus('Camera ready','green');

  // Wait for metadata to get dimensions
  await new Promise(r => {
    if (videoEl.readyState >= 2) return r();
    videoEl.onloadedmetadata = () => r();
  });
  overlay.width = videoEl.videoWidth || videoEl.clientWidth || 640;
  overlay.height = videoEl.videoHeight || Math.round(overlay.width * 4/3);

  // init detector if not
  if(!detector) {
    try {
      await initDetector();
    } catch(e){
      // if model fails, still allow manual capture without detection
      console.warn('Detector init failed, continuing without AI detection');
    }
  }

  startLoop();
  return true;
}

startBtn.onclick = async () => {
  // Small UX: disable button while starting
  startBtn.disabled = true;
  startBtn.textContent = '‚è≥ Starting...';
  const ok = await startCameraFlow();
  startBtn.disabled = false;
  startBtn.textContent = 'üì∏ Open Camera';
  if(!ok) {
    // show hint for Telegram users: open on mobile or in browser
    if (window.Telegram?.WebApp) {
      setInfo('Agar Telegram ichida bo‚Äòlsangiz: telefon ilovasida yoki browserda ochib ko‚Äòring.');
    }
  }
};

/* -------------------------
   Detection loop (MediaPipe)
   ------------------------- */
let lastVertices = null;
let loopRunning = false;

async function startLoop(){
  if(loopRunning) return;
  loopRunning = true;

  async function step(){
    if (!stream) { loopRunning=false; return; }
    try {
      if (detector && typeof detector.detectForVideo === 'function') {
        const ts = performance.now();
        let result = null;
        try {
          result = detector.detectForVideo(videoEl, ts);
        } catch(e){
          console.warn('detectForVideo error', e);
          result = null;
        }

        if (result && result.documents && result.documents.length){
          const doc = result.documents[0];
          // prefer pageBoundingBox.normalizedVertices but fallback
          const normVerts = doc.pageBoundingBox?.normalizedVertices || doc.normalizedVertices || null;

          if(normVerts && normVerts.length===4){
            drawQuadOnOverlay(normVerts);
            setInfo('üìÑ Document detected');

            // stability check
            if(lastVertices){
              let dist=0;
              for(let i=0;i<4;i++){
                const pxA = { x: lastVertices[i].x*overlay.width, y: lastVertices[i].y*overlay.height };
                const pxB = { x: normVerts[i].x*overlay.width, y: normVerts[i].y*overlay.height };
                dist += Math.hypot(pxA.x-pxB.x, pxA.y-pxB.y);
              }
              if(dist < MOVE_THR) stableCount++; else stableCount=0;
            } else stableCount=0;

            lastVertices = normVerts;

            if(stableCount>=STABLE_FRAMES && !autoBusy){
              autoBusy=true;
              setInfo('Stable ‚Üí Auto capture');
              await captureAndStore(true);
              setTimeout(()=>{ autoBusy=false; }, 900);
            }
          } else {
            octx.clearRect(0,0,overlay.width,overlay.height);
            setInfo('Move closer & show the document');
            stableCount=0;
            lastVertices=null;
          }
        } else {
          octx.clearRect(0,0,overlay.width,overlay.height);
          setInfo('No document');
          stableCount=0;
          lastVertices=null;
        }
      } else {
        // Detector not available ‚Äî show hint and do nothing special
        octx.clearRect(0,0,overlay.width,overlay.height);
        setInfo('AI model not loaded ‚Äî tap Capture for manual photo');
        lastVertices=null;
        stableCount=0;
      }
    } catch(e){
      console.error('Loop overall error', e);
      setInfo('Detection error');
    }
    requestAnimationFrame(step);
  }
  requestAnimationFrame(step);
}

/* -------------------------
   Capture, perspective crop & enhancement
   ------------------------- */

captureBtn.onclick = ()=> captureAndStore(false);

async function captureAndStore(isAuto){
  if(!videoEl.videoWidth && !videoEl.clientWidth) return;
  setStatus(isAuto ? 'Auto capturing...' : 'Capturing...','yellow');

  // Draw current frame to canvas
  const base = document.createElement('canvas');
  base.width = videoEl.videoWidth || videoEl.clientWidth || 1280;
  base.height = videoEl.videoHeight || Math.round(base.width * 4/3);
  const bctx = base.getContext('2d');
  bctx.drawImage(videoEl,0,0,base.width,base.height);

  let finalCanvas = document.createElement('canvas');

  if(lastVertices && lastVertices.length===4){
    const src = lastVertices.map(v => ({ x: v.x * base.width, y: v.y * base.height }));
    const w1 = Math.hypot(src[1].x - src[0].x, src[1].y - src[0].y);
    const w2 = Math.hypot(src[2].x - src[3].x, src[2].y - src[3].y);
    const h1 = Math.hypot(src[3].x - src[0].x, src[3].y - src[0].y);
    const h2 = Math.hypot(src[2].x - src[1].x, src[2].y - src[1].y);
    let dstW = Math.round(Math.max(w1,w2));
    let dstH = Math.round(Math.max(h1,h2));
    const max = 1600;
    const scale = Math.min(1, max / Math.max(dstW,dstH));
    dstW = Math.round(dstW * scale);
    dstH = Math.round(dstH * scale);

    finalCanvas.width = dstW; finalCanvas.height = dstH;
    applyPerspectiveTransform(base, finalCanvas, src, dstW, dstH);
  } else {
    finalCanvas.width = base.width; finalCanvas.height = base.height;
    finalCanvas.getContext('2d').drawImage(base,0,0);
  }

  // Enhancement: simple auto-contrast + unsharp
  try { await enhanceCanvas(finalCanvas); } catch(e){ console.warn('Enhance failed', e); }

  const blob = await new Promise(res => finalCanvas.toBlob(res, 'image/jpeg', 0.95));
  const url = URL.createObjectURL(blob);
  images.push({ canvas: finalCanvas, blob, url });
  renderImages();
  saveAllBtn.classList.remove('hidden');
  setStatus(isAuto ? 'Auto captured' : 'Captured','green');
}

/* -------------------------
   Helper: perspective transform (projective)
   ------------------------- */
function applyPerspectiveTransform(srcCanvas, dstCanvas, srcPts, dstW, dstH){
  const dctx = dstCanvas.getContext('2d');

  function drawTri(srcTri, dstTri){
    const m = computeAffineTransform(srcTri, dstTri);
    dctx.save();
    dctx.beginPath();
    dctx.moveTo(dstTri[0].x,dstTri[0].y);
    dctx.lineTo(dstTri[1].x,dstTri[1].y);
    dctx.lineTo(dstTri[2].x,dstTri[2].y);
    dctx.closePath();
    dctx.clip();
    dctx.setTransform(m.a, m.b, m.c, m.d, m.e, m.f);
    dctx.drawImage(srcCanvas, 0,0);
    dctx.setTransform(1,0,0,1,0,0);
    dctx.restore();
  }

  drawTri([ srcPts[0], srcPts[1], srcPts[2] ], [ {x:0,y:0}, {x:dstW,y:0}, {x:dstW,y:dstH} ]);
  drawTri([ srcPts[0], srcPts[2], srcPts[3] ], [ {x:0,y:0}, {x:dstW,y:dstH}, {x:0,y:dstH} ]);
}

function computeAffineTransform(srcTri, dstTri){
  const x0 = srcTri[0].x, y0 = srcTri[0].y;
  const x1 = srcTri[1].x, y1 = srcTri[1].y;
  const x2 = srcTri[2].x, y2 = srcTri[2].y;
  const u0 = dstTri[0].x, v0 = dstTri[0].y;
  const u1 = dstTri[1].x, v1 = dstTri[1].y;
  const u2 = dstTri[2].x, v2 = dstTri[2].y;

  const A = [
    [x0, y0, 1, 0,  0,  0],
    [0,  0,  0, x0, y0, 1],
    [x1, y1, 1, 0,  0,  0],
    [0,  0,  0, x1, y1, 1],
    [x2, y2, 1, 0,  0,  0],
    [0,  0,  0, x2, y2, 1]
  ];
  const B = [u0, v0, u1, v1, u2, v2];

  const M = A.map((row,i)=> row.concat([B[i]]));
  const n = 6;
  for(let i=0;i<n;i++){
    let maxr=i;
    for(let r=i+1;r<n;r++) if(Math.abs(M[r][i])>Math.abs(M[maxr][i])) maxr=r;
    if(Math.abs(M[maxr][i])<1e-9) continue;
    [M[i], M[maxr]] = [M[maxr], M[i]];
    const div = M[i][i];
    for(let j=i;j<=n;j++) M[i][j]/=div;
    for(let r=0;r<n;r++) if(r!==i){
      const mult = M[r][i];
      for(let c=i;c<=n;c++) M[r][c] -= mult*M[i][c];
    }
  }
  const sol = M.map(row=>row[n]);
  return { a:sol[0], b:sol[1], c:sol[2], d:sol[3], e:sol[4], f:sol[5] };
}

/* -------------------------
   Enhancement
   ------------------------- */
async function enhanceCanvas(canvas){
  const ctx = canvas.getContext('2d');
  const img = ctx.getImageData(0,0,canvas.width,canvas.height);
  const data = img.data;
  let min=255, max=0;
  for(let i=0;i<data.length;i+=4){
    const lum = 0.299*data[i] + 0.587*data[i+1] + 0.114*data[i+2];
    if(lum<min) min=lum;
    if(lum>max) max=lum;
  }
  const range = Math.max(1, max-min);
  for(let i=0;i<data.length;i+=4){
    data[i] = Math.min(255, Math.max(0, (data[i]-min)*255/range ));
    data[i+1] = Math.min(255, Math.max(0, (data[i+1]-min)*255/range ));
    data[i+2] = Math.min(255, Math.max(0, (data[i+2]-min)*255/range ));
  }
  ctx.putImageData(img,0,0);

  const copy = document.createElement('canvas');
  copy.width = canvas.width; copy.height = canvas.height;
  const cctx = copy.getContext('2d');
  cctx.filter = 'blur(1px)';
  cctx.drawImage(canvas,0,0);
  const blurred = cctx.getImageData(0,0,canvas.width,canvas.height);
  const bd = blurred.data;
  const id = ctx.getImageData(0,0,canvas.width,canvas.height);
  const idd = id.data;
  const amount = 0.6;
  for(let i=0;i<idd.length;i+=4){
    idd[i] = Math.min(255, idd[i] + (idd[i]-bd[i])*amount);
    idd[i+1] = Math.min(255, idd[i+1] + (idd[i+1]-bd[i+1])*amount);
    idd[i+2] = Math.min(255, idd[i+2] + (idd[i+2]-bd[i+2])*amount);
  }
  ctx.putImageData(id,0,0);
}

/* -------------------------
   Preview rendering + deletion
   ------------------------- */
function renderImages(){
  previewEl.innerHTML = '';
  images.forEach((it, idx) => {
    const block = document.createElement('div');
    block.className = 'bg-slate-800 p-2 rounded-xl border border-slate-700 flex items-center gap-3';
    const img = document.createElement('img');
    img.src = it.url;
    img.className = 'w-20 h-20 rounded-xl object-contain bg-black';
    const span = document.createElement('span');
    span.className = 'text-xs opacity-70';
    span.textContent = `Page ${idx+1}`;
    const del = document.createElement('button');
    del.className = 'ml-auto bg-red-600 px-2 py-1 rounded-full text-xs';
    del.textContent = 'üóë';
    del.onclick = ()=>{
      URL.revokeObjectURL(it.url);
      images.splice(idx,1);
      renderImages();
      if(images.length===0) saveAllBtn.classList.add('hidden');
    };
    block.appendChild(img);
    block.appendChild(span);
    block.appendChild(del);
    previewEl.appendChild(block);
  });
}

/* -------------------------
   Save all -> generate multi-page PDF
   ------------------------- */
saveAllBtn.onclick = async ()=>{
  if(images.length===0) return;
  setStatus('Preparing PDF...','yellow');
  const { jsPDF } = window.jspdf;
  const doc = new jsPDF({ unit:'px', format:[images[0].canvas.width, images[0].canvas.height] });

  for(let i=0;i<images.length;i++){
    const c = images[i].canvas;
    const dataUrl = c.toDataURL('image/jpeg', 0.95);
    if(i>0) doc.addPage([c.width, c.height]);
    doc.addImage(dataUrl, 'JPEG', 0,0, c.width, c.height);
  }
  doc.save('scans.pdf');
  setStatus('PDF ready','green');
};

/* -------------------------
   Cleanup
   ------------------------- */
window.addEventListener('beforeunload', ()=>{
  if(stream) stream.getTracks().forEach(t=>t.stop());
});
</script>
</body>
</html>
